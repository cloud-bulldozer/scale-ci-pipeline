- job:
    block-downstream: false
    block-upstream: false
    builders:
    - shell: |+
        set -o pipefail
        set -eux

        # get perf keys to access orchestration host and set ssh session options
        git clone https://${SSHKEY_TOKEN}@github.com/redhat-performance/perf-dept.git
        export PUBLIC_KEY=${WORKSPACE}/perf-dept/ssh_keys/id_rsa_pbench_ec2.pub
        export PRIVATE_KEY=${WORKSPACE}/perf-dept/ssh_keys/id_rsa_pbench_ec2
        export OPTIONS="-o StrictHostKeyChecking=no -o ServerAliveInterval=1 -o ConnectionAttempts=100"
        chmod 600 ${PRIVATE_KEY}

        # fetch the kubeconfig from the orchestration host
        echo "Fetching the  kubeconfig from the orchestration host"
        scp ${OPTIONS} -i ${PRIVATE_KEY} ${ORCHESTRATION_USER}@${ORCHESTRATION_HOST}:$HOME/.kube/config ${WORKSPACE}/kubeconfig
        export KUBECONFIG=${WORKSPACE}/kubeconfig

        # run tests
        pushd workloads/router-perf/
        ./run_router_test.sh
    concurrent: true
    description: |
      This test is a data-plane workload generator that runs http requests through HAProxy into deployed pods.
      This job is managed by https://github.com/openshift-scale/scale-ci-pipeline
    disabled: false
    name: ATS-SCALE-CI-HTTP
    node: scale-ci
    parameters:
    - string:
        default: ""
        description: Token to access private repo containing ssh keys.
        name: SSHKEY_TOKEN
    - string:
        default: ""
        description: The machine intended to run the oc commands and launch the workload.
        name: ORCHESTRATION_HOST
    - string:
        default: "root"
        description: The user for the Orchestration host.
        name: ORCHESTRATION_USER
    - string:
        default: "quay.io/openshift-scale/scale-ci-workload"
        description: Container image that runs the workload script.
        name: WORKLOAD_IMAGE
    - bool:
        default: false
        description: Enables/disables the node selector that places the workload job on the `pbench` node.
        name: WORKLOAD_JOB_NODE_SELECTOR
    - bool:
        default: false
        description: Enables/disables the toleration on the workload job to permit the `controller` taint.
        name: WORKLOAD_JOB_TAINT
    - bool:
        default: false
        description: Enables/disables running the workload pod as privileged.
        name: WORKLOAD_JOB_PRIVILEGED
    - string:
        default: "/root/.kube/config"
        description: Location(absolute path) of kubeconfig on orchestration host.
        name: KUBECONFIG_FILE
    - bool:
        default: false
        description: Enables/disables running the workload wrapped by pbench-user-benchmark. When enabled, pbench agents can then be enabled (ENABLE_PBENCH_AGENTS) for further instrumentation data and pbench-copy-results can be enabled (ENABLE_PBENCH_COPY) to export captured data for further analysis.
        name: PBENCH_INSTRUMENTATION
    - bool:
        default: false
        description: Enables/disables the collection of pbench data on the pbench agent pods. These pods are deployed by the tooling playbook.
        name: ENABLE_PBENCH_AGENTS
    - bool:
        default: false
        description: Enables/disables the copying of pbench data to a remote results server for further analysis.
        name: ENABLE_PBENCH_COPY
    - string:
        default: ""
        description: DNS address of the pbench results server.
        name: PBENCH_SERVER
    - string:
        default: ""
        description: Future use for pbench and prometheus scraper to place results into git repo that holds results data.
        name: SCALE_CI_RESULTS_TOKEN
    - string:
        default: 0
        description: Number of retries for Ansible to poll if the workload job has completed. Poll attempts delay 10s between polls with some additional time taken for each polling action depending on the orchestration host setup.
        name: JOB_COMPLETION_POLL_ATTEMPTS
    - string:
        default: 1router
        description: A label to append to pbench directories and mb result directories.
        name: HTTP_TEST_SUFFIX
    - string:
        default: 1
        description: How many workload generators to use.
        name: HTTP_TEST_LOAD_GENERATORS
    - string:
        default: ''
        description: Load-generator nodes described by an extended regular expression (use "oc get nodes" node names). If unset/empty, do not pin the workload generators to any nodes.
        name: HTTP_TEST_LOAD_GENERATOR_NODES
    - string:
        default: 10
        description: Number of projects to create for each type of application (4 types currently).
        name: HTTP_TEST_APP_PROJECTS
    - string:
        default: 1
        description: Number of templates to create per project.
        name: HTTP_TEST_APP_TEMPLATES
    - string:
        default: 120
        description: Run time of individual HTTP test iterations in seconds.
        name: HTTP_TEST_RUNTIME
    - string:
        default: 0
        description: Thread ramp-up time in seconds. Must be < HTTP_TEST_RUNTIME.
        name: HTTP_TEST_MB_RAMP_UP
    - string:
        default: 0
        description: Maximum delay between client requests in ms. Can be a list of numbers separated by commas.
        name: HTTP_TEST_MB_DELAY
    - bool:
        default: true
        description: Use TLS session reuse.
        name: HTTP_TEST_MB_TLS_SESSION_REUSE
    - string:
        default: GET
        description: HTTP method to use for backend servers (GET/POST).
        name: HTTP_TEST_MB_METHOD
    - string:
        default: 1024
        description: Backend server (200 OK) response document length.
        name: HTTP_TEST_MB_RESPONSE_SIZE
    - string:
        default: 1024
        description: Body length of POST requests in characters for backend servers.
        name: HTTP_TEST_MB_REQUEST_BODY_SIZE
    - string:
        default: mix
        description: "Perform the test for the following (comma-separated) route terminations: mix,http,edge,passthrough,reencrypt."
        name: HTTP_TEST_ROUTE_TERMINATION
    - bool:
        default: false
        description: Run only a single HTTP test to establish functionality. It also overrides HTTP_TEST_APP_PROJECTS and HTTP_TEST_APP_TEMPLATES.
        name: HTTP_TEST_SMOKE_TEST
    - bool:
        default: false
        description:  Delete all namespaces with application pods, services and routes created for the purposes of HTTP tests.
        name: HTTP_TEST_NAMESPACE_CLEANUP
    - string:
        default: quay.io/openshift-scale/http-stress
        description: HTTP workload generator container image.
        name: HTTP_TEST_STRESS_CONTAINER_IMAGE
    - string:
        default: quay.io/openshift-scale/nginx
        description:  HTTP server container image.
        name: HTTP_TEST_SERVER_CONTAINER_IMAGE
    - string:
        default: ""
        description: Username for elasticsearch instance
        name: ES_USER
    - string:
        default: ""
        description: Password for elasticsearch instance
        name: ES_PASSWORD
    - string:
        default: ""
        description: Elasticsearch server to store results
        name: ES_SERVER
    - string:
        default: ""
        description: Port number for the Elasticsearch server
        name: ES_PORT
    - bool:
        default: true
        description: Enable/Disable the ability to compare two uperf runs. If set to true, the next set of environment variables pertaining to the type of test are
        name: COMPARE
    - string:
        default: ""
        description: Username for elasticsearch instance
        name: ES_USER_BASELINE
    - string:
        default: ""
        description: Password for elasticsearch instance
        name: ES_PASSWORD_BASELINE
    - string:
        default: ""
        description: Name you would like to give your baseline cloud. It will appear as a header in the CSV file
        name: BASELINE_CLOUD_NAME
    - string:
        default: ""
        description: Elasticsearch server used used by the baseline run
        name: ES_SERVER_BASELINE
    - string:
        default: ""
        description: Port number for the elasticsearch server used by the baseline run
        name: ES_PORT_BASELINE
    - string:
        default: ""
        description: BASELINE_ROUTER_UUID
        name: Baseline UUID for router test
    - string:
        default: ""
        description: Accepeted deviation in percentage for throughput when compared to a baseline run
        name: THROUGHPUT_TOLERANCE
    - string:
        default: ""
        description: Accepeted deviation in percentage for latency when compared to a baseline run
        name: LATENCY_TOLERANCE
    - string:
        default: ""
        description: URL to check the status of the cluster using cerberus
        name: CERBERUS_URL
    - string:
        default: ""
        description: Email Id to which the results in google spreadsheet will be mailed.
        name: EMAIL_ID_FOR_RESULTS_SHEET
    - string:
        default: ""
        description: The path to service account key for communicating with Google API.
        name: GSHEET_KEY
    - string:
        default: ""
        description: Location to service account key for communicating with Google API.
        name: GSHEET_KEY_LOCATION
    - string:
        default: ""
        description: The ES server that houses gold-index. Format `user:pass@<es_server>:<es_port>
        name: ES_GOLD
    - string:
        default: ""
        description: The openshift version you want to compare the current run to
        name: GOLD_OCP_VERSION
    - string:
        default: "openshiftsdn"
        description: Compares the current run with gold-index with the sdn type of GOLD_SDN. Options are openshiftsdn and ovnkubernetes
        name: GOLD_SDN
    - bool:
        default: true
        description: If COMPARE is set to true and COMPARE_WITH_GOLD is set to true then the current run will be compared against our gold-index
        name: COMPARE_WITH_GOLD
    - string:
        default: ''
        description: ''
        name: JENKINS_USER
        trim: 'false'
    - string:
        default: ''
        description: ''
        name: JENKINS_API_TOKEN
        trim: 'false'
    - string:
        default: ''
        description: ''
        name: JENKINS_ES_SERVER
        trim: 'false'
    project-type: freestyle
    properties:
    - raw:
        xml: |
          <hudson.plugins.disk__usage.DiskUsageProperty plugin="disk-usage@0.28" />
    - raw:
        xml: |
          <com.dabsquared.gitlabjenkins.connection.GitLabConnectionProperty plugin="gitlab-plugin@1.5.3">
          <gitLabConnection />
          </com.dabsquared.gitlabjenkins.connection.GitLabConnectionProperty>
    - raw:
        xml: |
          <org.jenkinsci.plugins.ZMQEventPublisher.HudsonNotificationProperty plugin="zmq-event-publisher@0.0.5">
          <enabled>false</enabled>
          </org.jenkinsci.plugins.ZMQEventPublisher.HudsonNotificationProperty>
    - raw:
        xml: |
          <com.synopsys.arc.jenkins.plugins.ownership.jobs.JobOwnerJobProperty plugin="ownership@0.11.0">
          <ownership>
          <ownershipEnabled>true</ownershipEnabled>
          <primaryOwnerId>nelluri</primaryOwnerId>
          <coownersIds class="sorted-set" />
          </ownership>
          </com.synopsys.arc.jenkins.plugins.ownership.jobs.JobOwnerJobProperty>
    - raw:
        xml: |
          <com.sonyericsson.rebuild.RebuildSettings plugin="rebuild@1.27">
          <autoRebuild>false</autoRebuild>
          <rebuildDisabled>false</rebuildDisabled>
          </com.sonyericsson.rebuild.RebuildSettings>
    - raw:
        xml: |
          <hudson.plugins.throttleconcurrents.ThrottleJobProperty plugin="throttle-concurrents@2.0.1">
          <maxConcurrentPerNode>0</maxConcurrentPerNode>
          <maxConcurrentTotal>0</maxConcurrentTotal>
          <categories class="java.util.concurrent.CopyOnWriteArrayList" />
          <throttleEnabled>false</throttleEnabled>
          <throttleOption>project</throttleOption>
          <limitOneJobWithMatchingParams>false</limitOneJobWithMatchingParams>
          <paramsToUseForLimit />
          </hudson.plugins.throttleconcurrents.ThrottleJobProperty>
    publishers:
    - raw:
        xml: |
          <hudson.plugins.parameterizedtrigger.BuildTrigger plugin="parameterized-trigger@2.35.2">
          <configs>
          <hudson.plugins.parameterizedtrigger.BuildTriggerConfig>
          <configs>
          <hudson.plugins.parameterizedtrigger.NodeParameters />
          <hudson.plugins.parameterizedtrigger.PredefinedBuildParameters>
          <properties>SSHKEY_TOKEN=${SSHKEY_TOKEN}
          ORCHESTRATION_HOST=${ORCHESTRATION_HOST}
          ORCHESTRATION_USER=${ORCHESTRATION_USER}
          JENKINS_BUILD_TAG=${BUILD_TAG}
          JENKINS_NODE_NAME=${NODE_NAME}
          JENKINS_BUILD_URL=${BUILD_URL}
          ES_SERVER=${JENKINS_ES_SERVER}
          JENKINS_USER=${JENKINS_USER}
          JENKINS_API_TOKEN=${JENKINS_API_TOKEN}</properties>
          <textParamValueOnNewLine>false</textParamValueOnNewLine>
          </hudson.plugins.parameterizedtrigger.PredefinedBuildParameters>
          </configs>
          <projects>INDEXER, </projects>
          <condition>ALWAYS</condition>
          <triggerWithNoParameters>false</triggerWithNoParameters>
          <triggerFromChildProjects>false</triggerFromChildProjects>
          </hudson.plugins.parameterizedtrigger.BuildTriggerConfig>
          </configs>
          </hudson.plugins.parameterizedtrigger.BuildTrigger>
    scm:
    - git:
        branches:
        - '*/master'
        url: https://github.com/cloud-bulldozer/plow.git
    triggers: []
    wrappers:
    - workspace-cleanup:
        dirmatch: false
    - ansicolor:
        colormap: xterm
