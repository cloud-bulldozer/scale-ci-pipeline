- job:
    block-downstream: false
    block-upstream: false
    builders:
    - shell: |+
        set -o pipefail
        set -eux

        git clone --depth=1 https://${SSHKEY_TOKEN}@github.com/redhat-performance/perf-dept.git
        export PUBLIC_KEY=${WORKSPACE}/perf-dept/ssh_keys/id_rsa_pbench_ec2.pub
        export PRIVATE_KEY=${WORKSPACE}/perf-dept/ssh_keys/id_rsa_pbench_ec2
        chmod 600 ${PRIVATE_KEY}

        # Create inventory File:
        echo "[orchestration]" > inventory
        echo "${ORCHESTRATION_HOST}" >> inventory

        export ANSIBLE_FORCE_COLOR=true
        ansible --version
        cp ci/ocp_jetpack_vars.yml group_vars/all.yml
        cp ci/ocp_install_vars.yml vars/shift_stack_vars.yaml
        for (( iter=1; iter<=$JOB_ITERATIONS; iter++ ))
        do
        if [ $INSTALL_OSP == true ]
        then
        time ansible-playbook -vvv main.yml | tee $(date +"%Y%m%d-%H%M%S")-jetpack-install.timing
        ssh-copy-id -i ${PUBLIC_KEY} ${ORCHESTRATION_USER}@${ORCHESTRATION_HOST}
        else
        echo "[undercloud]" >> inventory
        echo "${ORCHESTRATION_HOST} ansible_user=${ORCHESTRATION_USER}" >> inventory
        time ansible-playbook -i inventory -vvv delete_single_ocp.yml | tee $(date +"%Y%m%d-%H%M%S")-jetpack-delete-ocp.timing
        time ansible-playbook -i inventory -vvv ocp_on_osp.yml -e platform=osp | tee $(date +"%Y%m%d-%H%M%S")-jetpack-install-ocp.timing
        fi
        git clone --depth=1 https://github.com/cloud-bulldozer/scale-ci-deploy.git
        cd scale-ci-deploy
        # disable openshift install as we already installed via jetpack
        export OPENSHIFT_INSTALL=false
        time ansible-playbook -i ../inventory -vvv OCP-4.X/install-on-osp.yml | tee $(date +"%Y%m%d-%H%M%S")-post-install.timing
        done
    concurrent: false
    description: |
      Installs and configures OCP 4.x cluster on OSP.
      This job is managed by https://github.com/openshift-scale/scale-ci-pipeline
    disabled: false
    name: ATS-SCALE-CI-OCP-OSP-DEPLOY
    node: jetpack
    parameters:
    - string:
        default: "root"
        description: The user for the Orchestration host.
        name: ORCHESTRATION_USER
    - string:
        default: ""
        description: Host with the kubeconfig and oc client.
        name: ORCHESTRATION_HOST
    - password:
        default: ""
        description: Token to access private repo containing ssh keys.
        name: SSHKEY_TOKEN
    - bool:
        default: true
        description: Installs OCP cluster on OSP.
        name: OPENSHIFT_INSTALL
    - bool:
        default: false
        description: Deploy fresh OSP.
        name: INSTALL_OSP
    - bool:
        default: false
        description: ''
        name: SCALE_CI_BUILD_TRIGGER
    - string:
        default: ''
        description: ''
        name: SCALE_CI_BUILD_TRIGGER_URL
    - string:
        default: "v1"
        description: openshift apiversion
        name: OPENSHIFT_INSTALL_APIVERSION
    - string:
        default: ""
        description: Path to the public key to add to each openshift host.
        name: OPENSHIFT_INSTALL_SSH_PUB_KEY_FILE
    - password:
        default: ""
        description: pull secret
        name: OPENSHIFT_INSTALL_PULL_SECRET
    - password:
        default: ""
        description: Registry token to talk to quay registry
        name: OPENSHIFT_INSTALL_QUAY_REGISTRY_TOKEN
    - string:
        default: ""
        description: Image registry to use to pull down the images
        name: OPENSHIFT_INSTALL_IMAGE_REGISTRY
    - password:
        default: ""
        description: Registry token to talk to the image registry registry being used
        name: OPENSHIFT_INSTALL_REGISTRY_TOKEN
    - bool:
        default: true
        description: Enables/disables infra node creation using machinesets
        name: OPENSHIFT_TOGGLE_INFRA_NODE
    - bool:
        default: true
        description: Enable mutable grafana instance
        name: ENABLE_DITTYBOPPER
    - string:
        default: "~/.kube/config"
        description: path to the kubeconfig
        name: KUBECONFIG_PATH
    - string:
        default: ""
        description: Scale lab cloud name to use.
        name: SCALE_LAB_CLOUD_NAME
    - password:
        default: ''
        description: ansible ssh password.
        name: ANSIBLE_SSH_PASSWORD
    - string:
        default: '16'
        description: OSP version to install
        name: OPENSTACK_VERSION
    - bool:
        default: false
        description: use external network
        name: OSP_PUBLIC_EXTERNAL_INTERFACE
    - string:
        default: 'nova'
        description: public network interface name
        name: OSP_PUBLIC_NETWORK_NAME
    - string:
        default: ''
        description: external network gateway
        name: OSP_EXTERNAL_GATEWAY
    - string:
        default: ''
        description: external network cidr
        name: OSP_EXTERNAL_NET_CIDR
    - string:
        default: ''
        description: external allocation pools start
        name: OSP_EXTERNAL_ALLOCATION_POOLS_START
    - string:
        default: ''
        description: external allocation pools end
        name: OSP_EXTERNAL_ALLOCATION_POOLS_END
    - string:
        default: ''
        description: external interface default route
        name: OSP_EXTERNAL_INTERFACE_DEFAULT_ROUTE
    - string:
        default: ""
        description: Base domain for OCP install.
        name: OPENSHIFT_BASE_DOMAIN
    - string:
        default: ""
        description: openshift cluster name.
        name: OPENSHIFT_CLUSTER_NAME
    - string:
        default: ""
        description: openshift release number to deploy
        name: OPENSHIFT_RELEASE
    - string:
        default: "3"
        description: openshift master node count.
        name: OPENSHIFT_MASTER_COUNT
    - string:
        default: "5"
        description: openshift worker node count.
        name: OPENSHIFT_WORKER_COUNT
    - string:
        default: "nvme"
        description: openshift master instance type.
        name: OPENSHIFT_MASTER_INSTANCE_TYPE
    - string:
        default: "m4.xlarge"
        description: openshift worker instance type.
        name: OPENSHIFT_WORKER_INSTANCE_TYPE
    - string:
        default: ""
        description: openshift master root volume size.
        name: OPENSHIFT_MASTER_ROOT_VOLUME_SIZE
    - string:
        default: ""
        description: openshift master root volume type.
        name: OPENSHIFT_MASTER_ROOT_VOLUME_TYPE
    - string:
        default: "0"
        description: openshift master root volume iops
        name: OPENSHIFT_MASTER_ROOT_VOLUME_IOPS
    - string:
        default: "64"
        description: openshift worker root volume size
        name: OPENSHIFT_WORKER_ROOT_VOLUME_SIZE
    - string:
        default: ""
        description: openshift worker root volume type
        name: OPENSHIFT_WORKER_ROOT_VOLUME_TYPE
    - string:
        default: "0"
        description: openshift worker root volume iops
        name: OPENSHIFT_WORKER_ROOT_VOLUME_IOPS
    - string:
        default: "10.128.0.0/14"
        description: openshift install cidr
        name: OPENSHIFT_CIDR
    - string:
        default: "10.0.0.0/16"
        description: openshift install machine cidr
        name: OPENSHIFT_MACHINE_CIDR
    - string:
        default: ""
        description: The network type used for the cluster, for OVS it is OpenShiftSDN and for OVN it is OVNKubernetes.
        name: OPENSHIFT_NETWORK_TYPE
    - string:
        default: "172.30.0.0/16"
        description: openshift install service network
        name: OPENSHIFT_SERVICE_NETWORK
    - string:
        default: "23"
        description: openshift install host prefix
        name: OPENSHIFT_HOST_PREFIX
    - bool:
        default: false
        description: Creates workload and infra nodes post install.
        name: OPENSHIFT_POST_INSTALL
    - string:
        default: "600"
        description: Poll attempts to finish post install before failing
        name: OPENSHIFT_POST_INSTALL_POLL_ATTEMPTS
    - bool:
        default: true
        description: Enables/Disables dedicated workload node creation using machinesets
        name: OPENSHIFT_TOGGLE_WORKLOAD_NODE
    - string:
        default: "machine.openshift.io"
        description: Machineset label prefix
        name: MACHINESET_METADATA_LABEL_PREFIX
    - string:
        default: "m4.xlarge"
        description: Infra node instance type
        name: OPENSHIFT_INFRA_NODE_INSTANCE_TYPE
    - string:
        default: "m4.xlarge"
        description: Workload node instance type
        name: OPENSHIFT_WORKLOAD_NODE_INSTANCE_TYPE
    - string:
        default: "64"
        description: Workload node volume size
        name: OPENSHIFT_WORKLOAD_NODE_VOLUME_SIZE
    - string:
        default: ""
        description: Workload node volume type
        name: OPENSHIFT_WORKLOAD_NODE_VOLUME_TYPE
    - string:
        default: "0"
        description: Workload node volume IOPS
        name: OPENSHIFT_WORLOAD_NODE_VOLUME_IOPS
    - string:
        default: "15d"
        description: Retention period for the prometheus data
        name: OPENSHIFT_PROMETHEUS_RETENTION_PERIOD
    - string:
        default: "standard"
        description: Prometheus stprage class
        name: OPENSHIFT_PROMETHEUS_STORAGE_CLASS
    - string:
        default: "10Gi"
        description: Prometheus storage size
        name: OPENSHIFT_PROMETHEUS_STORAGE_SIZE
    - string:
        default: "standard"
        description: Alertmanager storage class
        name: OPENSHIFT_ALERTMANAGER_STORAGE_CLASS
    - string:
        default: "2Gi"
        description: Alertmanager storage size
        name: OPENSHIFT_ALERTMANAGER_STORAGE_SIZE
    - bool:
        default: false
        description: Configures the cluster to enable running workloads.
        name: OPENSHIFT_POST_CONFIG
    - bool:
        default: false
        description: Enables debugging i.e ssh to the cluster nodes.
        name: OPENSHIFT_DEBUG_CONFIG
    - string:
        default: "~/cerberus.yaml"
        description: path to the cerberus config
        name: CERBERUS_CONFIG_PATH
    - bool:
        default: false
        description: Enable Cerberus
        name: CERBERUS_ENABLE
    - string:
        default: "quay.io/openshift-scale/cerberus:latest"
        description: cerberus image
        name: CERBERUS_IMAGE
    - string:
        default: "http://0.0.0.0:8080"
        description: Cerberus url where the go/no-go signal is exposed
        name: CERBERUS_URL
    - bool:
        default: true
        description: cerberus will watch the nodes when enabled
        name: WATCH_NODES
    - bool:
        default: true
        description: cerberus will watch cluster operators when enabled
        name: WATCH_CLUSTER_OPERATORS
    - bool:
        default: true
        description: cerberus will launch a simple http server to expose the go/no-go signal when enabled
        name: CERBERUS_PUBLISH_STATUS
    - bool:
        default: false
        description: cerberus will run inspection on the failed components when enabled. This assumes that the distribution is ocp vs kube.
        name: INSPECT_COMPONENTS
    - bool:
        default: false
        description: cerberus will report the failures on slack when enabled
        name: SLACK_INTEGRATION
    - string:
        default: ""
        description: slack token to talk the api
        name: SLACK_API_TOKEN
    - string:
        default: ""
        description: slack channel to report the failures
        name: SLACK_CHANNEL
    - string:
        default: "{Monday: , Tuesday: , Wednesday: , Thursday: , Friday: , Saturday: , Sunday: }"
        description: list of watcher id's to ping in case of failures
        name: WATCHER_SLACK_ID
    - string:
        default: ""
        description: slack alias to ping when watcher id's are not defined
        name: SLACK_TEAM_ALIAS
    - string:
        default: "5"
        description: number of iterations to run when daemon mode is not enabled
        name: ITERATIONS
    - string:
        default: "30"
        description: duration to sleep/wait between each iteration
        name: SLEEP_TIME
    - bool:
        default: true
        description: when enabled will run cerberus forever
        name: DAEMON_MODE
    - string:
        default: ""
        description: Path to the auth dir where the kubeconfig exists, this var is used with flexy install jobs.
        name: KUBECONFIG_AUTH_DIR_PATH
    - string:
        default: "1"
        description: Number of iterations to run the job
        name: JOB_ITERATIONS
    - string:
        default: ''
        description: ''
        name: JENKINS_USER
        trim: 'false'
    - string:
        default: ''
        description: ''
        name: JENKINS_API_TOKEN
        trim: 'false'
    - string:
        default: ''
        description: ''
        name: JENKINS_ES_SERVER
        trim: 'false'
    project-type: freestyle
    properties:
    - raw:
        xml: |
          <hudson.plugins.disk__usage.DiskUsageProperty plugin="disk-usage@0.28" />
    - raw:
        xml: |
          <com.dabsquared.gitlabjenkins.connection.GitLabConnectionProperty plugin="gitlab-plugin@1.5.3">
          <gitLabConnection />
          </com.dabsquared.gitlabjenkins.connection.GitLabConnectionProperty>
    - raw:
        xml: |
          <org.jenkinsci.plugins.ZMQEventPublisher.HudsonNotificationProperty plugin="zmq-event-publisher@0.0.5">
          <enabled>false</enabled>
          </org.jenkinsci.plugins.ZMQEventPublisher.HudsonNotificationProperty>
    - raw:
        xml: |
          <com.synopsys.arc.jenkins.plugins.ownership.jobs.JobOwnerJobProperty plugin="ownership@0.11.0">
          <ownership>
          <ownershipEnabled>true</ownershipEnabled>
          <primaryOwnerId>nelluri</primaryOwnerId>
          <coownersIds class="sorted-set" />
          </ownership>
          </com.synopsys.arc.jenkins.plugins.ownership.jobs.JobOwnerJobProperty>
    - raw:
        xml: |
          <com.sonyericsson.rebuild.RebuildSettings plugin="rebuild@1.27">
          <autoRebuild>false</autoRebuild>
          <rebuildDisabled>false</rebuildDisabled>
          </com.sonyericsson.rebuild.RebuildSettings>
    - raw:
        xml: |
          <hudson.plugins.throttleconcurrents.ThrottleJobProperty plugin="throttle-concurrents@2.0.1">
          <maxConcurrentPerNode>0</maxConcurrentPerNode>
          <maxConcurrentTotal>0</maxConcurrentTotal>
          <categories class="java.util.concurrent.CopyOnWriteArrayList" />
          <throttleEnabled>false</throttleEnabled>
          <throttleOption>project</throttleOption>
          <limitOneJobWithMatchingParams>false</limitOneJobWithMatchingParams>
          <paramsToUseForLimit />
          </hudson.plugins.throttleconcurrents.ThrottleJobProperty>
    publishers:
    - archive:
        allow-empty: true
        artifacts: '*.timing'
        case-sensitive: true
        default-excludes: true
        fingerprint: false
        only-if-success: false
    - raw:
        xml: |
          <hudson.plugins.parameterizedtrigger.BuildTrigger plugin="parameterized-trigger@2.35.2">
          <configs>
          <hudson.plugins.parameterizedtrigger.BuildTriggerConfig>
          <configs>
          <hudson.plugins.parameterizedtrigger.NodeParameters />
          <hudson.plugins.parameterizedtrigger.PredefinedBuildParameters>
          <properties>SSHKEY_TOKEN=${SSHKEY_TOKEN}
          ORCHESTRATION_HOST=${ORCHESTRATION_HOST}
          ORCHESTRATION_USER=${ORCHESTRATION_USER}
          JENKINS_BUILD_TAG=${BUILD_TAG}
          JENKINS_NODE_NAME=${NODE_NAME}
          JENKINS_BUILD_URL=${BUILD_URL}
          ES_SERVER=${JENKINS_ES_SERVER}
          JENKINS_USER=${JENKINS_USER}
          JENKINS_API_TOKEN=${JENKINS_API_TOKEN}</properties>
          <textParamValueOnNewLine>false</textParamValueOnNewLine>
          </hudson.plugins.parameterizedtrigger.PredefinedBuildParameters>
          </configs>
          <projects>INDEXER, </projects>
          <condition>ALWAYS</condition>
          <triggerWithNoParameters>false</triggerWithNoParameters>
          <triggerFromChildProjects>false</triggerFromChildProjects>
          </hudson.plugins.parameterizedtrigger.BuildTriggerConfig>
          </configs>
          </hudson.plugins.parameterizedtrigger.BuildTrigger>
    scm:
    - git:
        branches:
        - '*/master'
        url: https://github.com/redhat-performance/jetpack.git
    triggers: []
    wrappers:
    - workspace-cleanup:
        dirmatch: false
    - ansicolor:
        colormap: xterm
